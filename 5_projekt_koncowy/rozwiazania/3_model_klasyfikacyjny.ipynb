{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt - model klasyfikacyjny\n",
    "\n",
    "Cel projektu: Stworzenie systemu do alertów (progonozowanie czy wypożyczeń będzie więcej niż zwrotów).\n",
    "Alert powinien dotyczy kolejnej godziny. Tak, aby móc wysłać pracowników w rejony z niedoborem rowerów i przewieźć tam rezerwowe rowery lub pojazdów z innych lokalizacji.\n",
    "\n",
    "Zadania do realizacji\n",
    "1. Data preprocessing:\n",
    "    - Pobranie danych\n",
    "    - Filtrowanie danych (jaka historia będzie nam potrzebna do modelowania?).\n",
    "    - Połączenie danych:\n",
    "        - Jaki powinien być typ połączenia?\n",
    "        - Jak uzupełnić braki danych w kolumnach departure name oraz date?\n",
    "    - Wstępne sprawdzenie danych.\n",
    "    - Resampling danych na dane godzinowe oraz uzupełnienie braków danych.\n",
    "    - Stworzenie nowej zmiennej kategorycznej (y): Czy liczba wypożyczeń w bieżącej godzinie jest większa niż liczba zwrotów.\n",
    "    - Stworzenie zmiennych z daty: godzina,miesiąc, kwartał.\n",
    "    - Enkoding zmiennej departure name\n",
    "    - Stworzenie lagów (wartości z poprzednich okresów):\n",
    "        - Wartości dla danej stacji z poprzednich godzin / dni\n",
    "        - Zastanów się nad innymi przekształceniami i agregacjami zmiennych.\n",
    "        - Stwórz funkcję do przygotowania zmiennych.\n",
    "    - Filtrowanie zbioru:\n",
    "        - Czy potrzebujemy mieć wszystkie miesiące?\n",
    "        - Czy model będzie działać o każdej porze dnia?\n",
    "        - Czy chcemy modelować wszystkie stacje?\n",
    "    - Selekcja zmiennych\n",
    "    - Detekcja outlierów.\n",
    "    - Pamiętaj, aby usuwać zbędne obiekty, gdyż może Ci nie wystarczyć pamięci do przetwarzania.\n",
    "2. Optymalizacja modelu:\n",
    "    - Wykorzystanie jednego z poznanych algorytmów optymalizacyjnych.\n",
    "    - W przypadku niezadowalających wyników, testy na innym algorytmie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data preprocessing\n",
    "- Pobranie danych\n",
    "- Filtrowanie danych (jaka historia będzie nam potrzebna do modelowania?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych - liczba wypożyczeń\n",
    "df_dep = pd.read_parquet('data/hourly_data_per_station.parquet')\n",
    "df_dep = df_dep[df_dep['departure_date_hours']>='2018-01-01'].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych - liczba zwrotów\n",
    "df_ret = pd.read_parquet('data/hourly_data_per_station_returns.parquet')\n",
    "df_ret = df_ret[df_ret['return_date_hours']>='2018-01-01'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Połączenie danych:\n",
    "    - Jaki powinien być typ połączenia?\n",
    "    - Jak uzupełnić braki danych w kolumnach departure name oraz date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polaczenie danych\n",
    "df_merged = df_dep.merge(df_ret,\n",
    "                         left_on = ['departure_name','departure_date_hours'],\n",
    "                         right_on=['return_name','return_date_hours'],\n",
    "                         how = 'outer',\n",
    "                         suffixes=('_dep','_ret'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wielkosci poszczegolnych ramek\n",
    "print(df_dep.shape)\n",
    "print(df_ret.shape)\n",
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wartosci puste\n",
    "df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputacja danych - departure name/ date oraz temperature\n",
    "df_merged['departure_name'] = df_merged['departure_name'].fillna(df_merged['return_name'])\n",
    "df_merged['departure_date_hours'] = df_merged['departure_date_hours'].fillna(df_merged['return_date_hours'])\n",
    "df_merged['Air temperature (degC)'] = df_merged['Air temperature (degC)_dep'].fillna(df_merged['Air temperature (degC)_ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie braków danych\n",
    "df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuniecie zbędnych kolumn i ramek\n",
    "del df_merged['return_date_hours']\n",
    "del df_merged['return_name']\n",
    "del df_merged['Air temperature (degC)_dep']\n",
    "del df_merged['Air temperature (degC)_ret']\n",
    "del df_ret\n",
    "del df_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wstępne sprawdzenie danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe\n",
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie niepoprawnych wartosci\n",
    "df_merged[df_merged['distance (m)_dep']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[df_merged['distance (m)_ret']<0,'distance (m)_ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[df_merged['avg_speed (km/h)_dep']<0,'avg_speed (km/h)_dep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[df_merged['avg_speed (km/h)_ret']<0,'avg_speed (km/h)_ret'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zastąpienie niepoprawnych wartości średnią\n",
    "df_merged.loc[df_merged['distance (m)_dep']<0,'distance (m)_dep'] = df_merged['distance (m)_dep'].mean()\n",
    "df_merged.loc[df_merged['distance (m)_ret']<0,'distance (m)_ret'] = df_merged['distance (m)_ret'].mean()\n",
    "df_merged.loc[df_merged['avg_speed (km/h)_dep']<0,'avg_speed (km/h)_dep'] = df_merged['avg_speed (km/h)_dep'].mean()\n",
    "df_merged.loc[df_merged['avg_speed (km/h)_ret']<0,'avg_speed (km/h)_ret'] = df_merged['avg_speed (km/h)_ret'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zastąpienie niepoprawnych wartości średnią\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resampling danych na dane godzinowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample\n",
    "df_merged = df_merged.set_index('departure_date_hours').groupby('departure_name').resample('h').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uzupełnienie braków danych\n",
    "df_merged['Air temperature (degC)'] = df_merged['Air temperature (degC)'].fillna(-999)\n",
    "df_merged =df_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konwersja float na int\n",
    "df_merged[['numbers_of_departures','number_of_returns']] = df_merged[['numbers_of_departures','number_of_returns']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stworzenie nowej zmiennej kategorycznej (y): Czy liczba wypożyczeń w bieżącej godzinie jest większa niż liczba zwrotów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmienna y kategoryczna\n",
    "df_merged['y_cat'] = ((df_merged['numbers_of_departures']-1)> df_merged['number_of_returns']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udział wartosci y\n",
    "df_merged['y_cat'].value_counts() / df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Stworzenie zmiennych z daty: godzina, dzien, miesiąc, kwartał."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['hours'] = df_merged['departure_date_hours'].dt.hour\n",
    "df_merged['day'] = df_merged['departure_date_hours'].dt.day\n",
    "df_merged['month'] = df_merged['departure_date_hours'].dt.month\n",
    "df_merged['quarter'] = df_merged['departure_date_hours'].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Enkoding zmiennej departure name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obiekt ordinalencoder\n",
    "oe = OrdinalEncoder().fit(df_merged[['departure_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodanie zmiennej enkodowanej\n",
    "df_merged['departure_name_encoded'] = oe.transform(df_merged[['departure_name']]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzenie - head\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stworzenie lagów (wartości z poprzednich okresów):\n",
    "    - Wartości dla danej stacji z poprzednich godzin / dni\n",
    "    - Zastanów się nad innymi przekształceniami i agregacjami zmiennych.\n",
    "    - Stwórz funkcję do przygotowania zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobranie stworzonych funkcji\n",
    "from help_function import lag_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nazwy kolumn do lagów\n",
    "lag_cols = ['numbers_of_departures',\n",
    "       'distance (m)_dep', 'duration (sec.)_dep', 'avg_speed (km/h)_dep',\n",
    "       'number_of_returns', 'distance (m)_ret', 'duration (sec.)_ret',\n",
    "       'avg_speed (km/h)_ret', 'Air temperature (degC)', 'y_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stworzenie różnych lagów\n",
    "for i in [1,2,3,6,9,12,24]:\n",
    "    df_merged = lag_n(df = df_merged,\n",
    "                      group_col='departure_name',\n",
    "                      lag_cols=lag_cols,\n",
    "                      sort_by='departure_date_hours',\n",
    "                      lag_number=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zastąpienie braków danych w temperaturze, wartością sprzed godziny\n",
    "df_merged.loc[df_merged['Air temperature (degC)']==-999,'Air temperature (degC)'] = df_merged.loc[df_merged['Air temperature (degC)']==-999,\n",
    "                                                                                                  'Air temperature (degC)_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zastąpienie braków danych w temperaturze, wartością sprzed 2 godzin\n",
    "df_merged.loc[df_merged['Air temperature (degC)']==-999,'Air temperature (degC)'] = df_merged.loc[df_merged['Air temperature (degC)']==-999,\n",
    "                                                                                                  'Air temperature (degC)_lag_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stworzenie funkcji prepare data, która przetworzy ramkę danych i doda do niej wymagane zmienne do późniejszej predykcji modelu\n",
    "def prepare_data(df,lag_cols):\n",
    "    df = df.set_index('departure_date_hours').groupby('departure_name').resample('h').mean().reset_index()\n",
    "    df['Air temperature (degC)'] = df['Air temperature (degC)'].fillna(-999)\n",
    "    df =df.fillna(0)\n",
    "    df['y_cat'] = ((df['numbers_of_departures']-1)> df['number_of_returns']).astype(int)\n",
    "    if not set(lag_cols).issubset(df.columns):\n",
    "        raise KeyError('Given dataframe does not contain required fields.')\n",
    "    df['hour'] = df['departure_date_hours'].dt.hour\n",
    "    df['day'] = df['departure_date_hours'].dt.day\n",
    "    df['month'] = df['departure_date_hours'].dt.month\n",
    "    df['quarter'] = df['departure_date_hours'].dt.quarter\n",
    "    for i in [1,2,3,6,9,12,24]:\n",
    "        df = lag_n(df = df,\n",
    "                      group_col='departure_name',\n",
    "                      lag_cols=lag_cols,\n",
    "                      sort_by='departure_date_hours',\n",
    "                      lag_number=i)\n",
    "    df.loc[df['Air temperature (degC)']==-999,'Air temperature (degC)'] = df.loc[df['Air temperature (degC)']==-999,\n",
    "                                                                                                  'Air temperature (degC)_lag_1']\n",
    "    df.loc[df['Air temperature (degC)']==-999,'Air temperature (degC)'] = df.loc[df['Air temperature (degC)']==-999,\n",
    "                                                                                                  'Air temperature (degC)_lag_2']\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['departure_name', 'departure_date_hours', 'numbers_of_departures',\n",
       "       'distance (m)_dep', 'duration (sec.)_dep', 'avg_speed (km/h)_dep',\n",
       "       'number_of_returns', 'distance (m)_ret', 'duration (sec.)_ret',\n",
       "       'avg_speed (km/h)_ret', 'Air temperature (degC)', 'y_cat', 'hours',\n",
       "       'day', 'month', 'quarter', 'departure_name_encoded',\n",
       "       'numbers_of_departures_lag_1', 'distance (m)_dep_lag_1',\n",
       "       'duration (sec.)_dep_lag_1', 'avg_speed (km/h)_dep_lag_1',\n",
       "       'number_of_returns_lag_1', 'distance (m)_ret_lag_1',\n",
       "       'duration (sec.)_ret_lag_1', 'avg_speed (km/h)_ret_lag_1',\n",
       "       'Air temperature (degC)_lag_1', 'y_cat_lag_1',\n",
       "       'numbers_of_departures_lag_2', 'distance (m)_dep_lag_2',\n",
       "       'duration (sec.)_dep_lag_2', 'avg_speed (km/h)_dep_lag_2',\n",
       "       'number_of_returns_lag_2', 'distance (m)_ret_lag_2',\n",
       "       'duration (sec.)_ret_lag_2', 'avg_speed (km/h)_ret_lag_2',\n",
       "       'Air temperature (degC)_lag_2', 'y_cat_lag_2',\n",
       "       'numbers_of_departures_lag_3', 'distance (m)_dep_lag_3',\n",
       "       'duration (sec.)_dep_lag_3', 'avg_speed (km/h)_dep_lag_3',\n",
       "       'number_of_returns_lag_3', 'distance (m)_ret_lag_3',\n",
       "       'duration (sec.)_ret_lag_3', 'avg_speed (km/h)_ret_lag_3',\n",
       "       'Air temperature (degC)_lag_3', 'y_cat_lag_3',\n",
       "       'numbers_of_departures_lag_6', 'distance (m)_dep_lag_6',\n",
       "       'duration (sec.)_dep_lag_6', 'avg_speed (km/h)_dep_lag_6',\n",
       "       'number_of_returns_lag_6', 'distance (m)_ret_lag_6',\n",
       "       'duration (sec.)_ret_lag_6', 'avg_speed (km/h)_ret_lag_6',\n",
       "       'Air temperature (degC)_lag_6', 'y_cat_lag_6',\n",
       "       'numbers_of_departures_lag_9', 'distance (m)_dep_lag_9',\n",
       "       'duration (sec.)_dep_lag_9', 'avg_speed (km/h)_dep_lag_9',\n",
       "       'number_of_returns_lag_9', 'distance (m)_ret_lag_9',\n",
       "       'duration (sec.)_ret_lag_9', 'avg_speed (km/h)_ret_lag_9',\n",
       "       'Air temperature (degC)_lag_9', 'y_cat_lag_9',\n",
       "       'numbers_of_departures_lag_12', 'distance (m)_dep_lag_12',\n",
       "       'duration (sec.)_dep_lag_12', 'avg_speed (km/h)_dep_lag_12',\n",
       "       'number_of_returns_lag_12', 'distance (m)_ret_lag_12',\n",
       "       'duration (sec.)_ret_lag_12', 'avg_speed (km/h)_ret_lag_12',\n",
       "       'Air temperature (degC)_lag_12', 'y_cat_lag_12',\n",
       "       'numbers_of_departures_lag_24', 'distance (m)_dep_lag_24',\n",
       "       'duration (sec.)_dep_lag_24', 'avg_speed (km/h)_dep_lag_24',\n",
       "       'number_of_returns_lag_24', 'distance (m)_ret_lag_24',\n",
       "       'duration (sec.)_ret_lag_24', 'avg_speed (km/h)_ret_lag_24',\n",
       "       'Air temperature (degC)_lag_24', 'y_cat_lag_24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wywołanie funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wywołanie funkcji\n",
    "df_merged_2 = prepare_data(df_merged[['departure_name', 'departure_date_hours', 'numbers_of_departures',\n",
    "       'distance (m)_dep', 'duration (sec.)_dep', 'avg_speed (km/h)_dep',\n",
    "       'number_of_returns', 'distance (m)_ret', 'duration (sec.)_ret',\n",
    "       'avg_speed (km/h)_ret', 'Air temperature (degC)', 'y_cat', 'hours',\n",
    "       'day', 'month', 'quarter', 'departure_name_encoded']],lag_cols = lag_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df_merged_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "print(df_merged.shape)\n",
    "print(df_merged_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzenie listy kolumn\n",
    "df_merged_2.columns == df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybranie 1 stacji\n",
    "st = df_merged.departure_name.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie metryk dla 1 stacji\n",
    "df_merged[df_merged['departure_name']==st].sort_values('departure_date_hours').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuniecie jednej ramki \n",
    "del df_merged_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtrowanie zbioru:\n",
    "    - Czy potrzebujemy mieć wszystkie miesiące?\n",
    "    - Czy model będzie działać o każdej porze dnia?\n",
    "    - Czy chcemy modelować wszystkie stacje?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stworzenie daty z dokładnoscia do dnia\n",
    "df_merged['departure_date'] = pd.to_datetime(df_merged['departure_date_hours'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liczba wypożyczeń według miesięcy\n",
    "df_merged.groupby('month')['numbers_of_departures'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wybranie miesięcy z \"wysokiego\" sezonu\n",
    "df_merged = df_merged[df_merged.month.isin([5,6,7,8,9])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liczba wypożyczeń według departure_date_hours\n",
    "hours = df_merged.groupby('departure_date_hours')['numbers_of_departures'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyciągnięcie godziny\n",
    "hours['hour'] = hours['departure_date_hours'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# średnia liczba wypożyczeń per godzina\n",
    "hours.groupby('hour').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['hour'] = df_merged['hours'].copy()\n",
    "del df_merged['hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odfiltrowanie nieistotnych godzin\n",
    "df_merged = df_merged[(df_merged['hour']>=8) & (df_merged['hour']<=22)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimalna data dla każdej stacji\n",
    "min_date = df_merged.groupby('departure_name')['departure_date'].agg(['min','max']).reset_index().rename(\n",
    "    columns = {'min': 'min_date',\n",
    "               'max': 'max_date'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacje do odrzucenia \n",
    "stations_to_excluude = min_date[(min_date['min_date']>='2020-01-01') | (min_date['max_date']<'2020-01-01')]['departure_name'].values\n",
    "stations_to_excluude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrowanie\n",
    "df_merged = df_merged[~(df_merged['departure_name'].isin(stations_to_excluude))].reset_index(drop=True)\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodanie min date do danych\n",
    "df_merged = df_merged.merge(min_date,on ='departure_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuniecie pierwszego dnia danych\n",
    "df_merged = df_merged[df_merged['departure_date']>df_merged['min_date']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selekcja zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kolumny w ramce danych\n",
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potencjalna lista zmiennych\n",
    "potential_x_names = [\n",
    "        'day',\n",
    "       'month', 'quarter', 'departure_name_encoded',\n",
    "       'numbers_of_departures_lag_1', 'distance (m)_dep_lag_1',\n",
    "       'duration (sec.)_dep_lag_1', 'avg_speed (km/h)_dep_lag_1',\n",
    "       'number_of_returns_lag_1', 'distance (m)_ret_lag_1',\n",
    "       'duration (sec.)_ret_lag_1', 'avg_speed (km/h)_ret_lag_1',\n",
    "       'Air temperature (degC)_lag_1', 'y_cat_lag_1',\n",
    "       'numbers_of_departures_lag_2', 'distance (m)_dep_lag_2',\n",
    "       'duration (sec.)_dep_lag_2', 'avg_speed (km/h)_dep_lag_2',\n",
    "       'number_of_returns_lag_2', 'distance (m)_ret_lag_2',\n",
    "       'duration (sec.)_ret_lag_2', 'avg_speed (km/h)_ret_lag_2',\n",
    "       'Air temperature (degC)_lag_2', 'y_cat_lag_2',\n",
    "       'numbers_of_departures_lag_3', 'distance (m)_dep_lag_3',\n",
    "       'duration (sec.)_dep_lag_3', 'avg_speed (km/h)_dep_lag_3',\n",
    "       'number_of_returns_lag_3', 'distance (m)_ret_lag_3',\n",
    "       'duration (sec.)_ret_lag_3', 'avg_speed (km/h)_ret_lag_3',\n",
    "       'Air temperature (degC)_lag_3', 'y_cat_lag_3',\n",
    "       'numbers_of_departures_lag_6', 'distance (m)_dep_lag_6',\n",
    "       'duration (sec.)_dep_lag_6', 'avg_speed (km/h)_dep_lag_6',\n",
    "       'number_of_returns_lag_6', 'distance (m)_ret_lag_6',\n",
    "       'duration (sec.)_ret_lag_6', 'avg_speed (km/h)_ret_lag_6',\n",
    "       'Air temperature (degC)_lag_6', 'y_cat_lag_6',\n",
    "       'numbers_of_departures_lag_9', 'distance (m)_dep_lag_9',\n",
    "       'duration (sec.)_dep_lag_9', 'avg_speed (km/h)_dep_lag_9',\n",
    "       'number_of_returns_lag_9', 'distance (m)_ret_lag_9',\n",
    "       'duration (sec.)_ret_lag_9', 'avg_speed (km/h)_ret_lag_9',\n",
    "       'Air temperature (degC)_lag_9', 'y_cat_lag_9',\n",
    "       'numbers_of_departures_lag_12', 'distance (m)_dep_lag_12',\n",
    "       'duration (sec.)_dep_lag_12', 'avg_speed (km/h)_dep_lag_12',\n",
    "       'number_of_returns_lag_12', 'distance (m)_ret_lag_12',\n",
    "       'duration (sec.)_ret_lag_12', 'avg_speed (km/h)_ret_lag_12',\n",
    "       'Air temperature (degC)_lag_12', 'y_cat_lag_12',\n",
    "       'numbers_of_departures_lag_24', 'distance (m)_dep_lag_24',\n",
    "       'duration (sec.)_dep_lag_24', 'avg_speed (km/h)_dep_lag_24',\n",
    "       'number_of_returns_lag_24', 'distance (m)_ret_lag_24',\n",
    "       'duration (sec.)_ret_lag_24', 'avg_speed (km/h)_ret_lag_24',\n",
    "       'Air temperature (degC)_lag_24', 'y_cat_lag_24', \n",
    "       'hour'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(potential_x_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model bazowy - drzewo decyzyjne\n",
    "model_base = DecisionTreeClassifier(max_depth=7, random_state=123).fit(df_merged[potential_x_names],df_merged['y_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "model_base.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liczba zmiennych, które nie były użyte\n",
    "(model_base.feature_importances_==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista finalnych zmiennych\n",
    "x_names = model_base.feature_names_in_[model_base.feature_importances_>0]\n",
    "x_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe wytypowanych zmiennych\n",
    "df_merged[x_names].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korelacja\n",
    "df_merged[list(x_names)+['y_cat']].corr(method='spearman')['y_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przykladowy wykres gestosci\n",
    "sns.kdeplot(data=df_merged, x='numbers_of_departures_lag_1',hue= 'y_cat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detekcja outlierów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja obiektu\n",
    "iso_forest = IsolationForest(bootstrap=True,random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "iso_forest.fit(df_merged[x_names[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predykcja outlierów\n",
    "is_outlier = iso_forest.predict(df_merged[x_names[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udział\n",
    "pd.Series(is_outlier).value_counts()/ len(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodanie outlierow do danych\n",
    "df_merged['outlier'] = is_outlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Optymalizacja modelu:\n",
    "    - Wykorzystanie jednego z poznanych algorytmów optymalizacyjnych.\n",
    "    - W przypadku niezadowalających wyników, testy na innym algorytmie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daty graniczne train/test/valid\n",
    "date_train = '2020-01-01'\n",
    "date_test = '2020-07-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usunięcie outliery\n",
    "df_merged = df_merged[df_merged['outlier']==1].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udział klas\n",
    "df_merged.y_cat.value_counts()/len(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podzial na train / test / valid\n",
    "train = df_merged[df_merged['departure_date']<date_train]\n",
    "test = df_merged[(df_merged['departure_date']>=date_train) & (df_merged['departure_date']<=date_test)]\n",
    "valid = df_merged[df_merged['departure_date']>date_test]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podzial na x/y\n",
    "train_x = train[x_names]\n",
    "train_y = train['y_cat']\n",
    "test_x  =test[x_names]\n",
    "test_y = test['y_cat']\n",
    "valid_x = valid[x_names]\n",
    "valid_y = valid['y_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobranie funkcji i bibliotek\n",
    "import optuna \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja optymalizacyjna\n",
    "def objective(trial):\n",
    "    params = {'max_iter': trial.suggest_int('max_iter',200,2000),\n",
    "              'max_depth': trial.suggest_int('max_depth',5,100),\n",
    "              'learning_rate': trial.suggest_float('learning_rate',0.01,0.9),\n",
    "              'min_samples_leaf': trial.suggest_int('min_samples_leaf',5,500)}\n",
    "    model = HistGradientBoostingClassifier(**params).fit(train_x,train_y)\n",
    "    preds = model.predict_proba(test_x)[:,1]\n",
    "    return roc_auc_score(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study\n",
    "study = optuna.create_study(direction='maximize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optymalizacja\n",
    "study.optimize(objective, n_trials=15, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# najlepsze parametry\n",
    "best_params= study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model \n",
    "final_model = HistGradientBoostingClassifier(**best_params).fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing  import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TargetEncoder().fit(train[['departure_name']],train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['departure_name_encoded_te'] = te.transform(train[['departure_name']])\n",
    "test['departure_name_encoded_te'] = te.transform(test[['departure_name']])\n",
    "valid['departure_name_encoded_te'] = te.transform(valid[['departure_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names_2 = list(x_names.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names_2.append('departure_name_encoded_te')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names_2 = x_names_2[1:]\n",
    "x_names_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podzial na x/y\n",
    "train_x = train[x_names_2]\n",
    "test_x  =test[x_names_2]\n",
    "valid_x = valid[x_names_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_te = HistGradientBoostingClassifier(**best_params).fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podzial na x/y\n",
    "train_x = train[potential_x_names]\n",
    "test_x  =test[potential_x_names]\n",
    "valid_x = valid[potential_x_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_all_f = HistGradientBoostingClassifier(**best_params).fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predykcje\n",
    "test_pred_1 = final_model.predict_proba(test[final_model.feature_names_in_])[:,1]\n",
    "test_pred_te = final_model_te.predict_proba(test[final_model_te.feature_names_in_])[:,1]\n",
    "test_pred_all_f  =final_model_all_f.predict_proba(test[final_model_all_f.feature_names_in_])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_all_f.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "print(roc_auc_score(test_y,test_pred_1))\n",
    "print(roc_auc_score(test_y,test_pred_te))\n",
    "print(roc_auc_score(test_y,test_pred_all_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_proba  =final_model.predict_proba(valid[final_model.feature_names_in_])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(valid_y,valid_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred  =final_model.predict(valid[final_model.feature_names_in_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation - classification report\n",
    "print(classification_report(valid_y,valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for i in np.arange(0,1,0.01):\n",
    "    valid_pred_proba_i = final_model.predict_proba(valid[final_model.feature_names_in_])[:,1]\n",
    "    valid_pred_i = (valid_pred_proba_i > i).astype(int)\n",
    "    acc_i = sum((valid_y == valid_pred_i).astype(int))\n",
    "    accuracy.append(acc_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_offs = np.arange(0,1,0.01)\n",
    "cut_off = cut_offs[accuracy.index(max(accuracy))]\n",
    "cut_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_new = (final_model.predict_proba(valid[final_model.feature_names_in_])[:,1] >cut_off).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_y,valid_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['pred_proba'] = final_model.predict_proba(df_merged[final_model.feature_names_in_])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyniki wg stacji\n",
    "results = df_merged.loc[df_merged['departure_date']>='2020-01-01',['y_cat','pred_proba','departure_name']].groupby('departure_name').apply(\n",
    "    lambda x: roc_auc_score(x['y_cat'], x['pred_proba']) \n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=0).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapis modelu\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(final_model, 'models/classification_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(oe, 'models/ordinal_encoder_for_classification.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
