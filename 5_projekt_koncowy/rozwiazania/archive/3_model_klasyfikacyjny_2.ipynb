{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt - model klasyfikacyjny\n",
    "\n",
    "Cel projektu: Stworzenie systemu do alertów (progonozowanie czy wypożyczeń będzie więcej niż zwrotów).\n",
    "Alert powinien dotyczy kolejnej godziny. Tak, aby móc wysłać pracowników w rejony z niedoborem rowerów i przewieźć tam rezerwowe rowery lub pojazdów z innych lokalizacji.\n",
    "\n",
    "Zadania do realizacji\n",
    "1. Data preprocessing:\n",
    "    - Pobranie danych\n",
    "    - Wstępne sprawdzenie danych.\n",
    "    - Przekodowanie zmiennej czasowej na datę\n",
    "    - Przekodowanie zmiennej departure_id oraz return_id na string\n",
    "    - Stworzenie zmiennych z daty: godzina,miesiąc, kwartał.\n",
    "    - Stworzenie nowej zmiennej kategorycznej (y): Czy liczba wypożyczeń w bieżącej godzinie jest większa niż liczba zwrotów.\n",
    "    - Enkoding zmiennej departure id\n",
    "    - Stworzenie lagów (wartości z poprzednich okresów):\n",
    "        - wartości dla danej stacji z poprzedniej godziny\n",
    "        - średnie wartości dla stacji z poprzedniego dnia\n",
    "        - średnie wartości ogółu z poprzedniego dnia i godziny\n",
    "    - Selekcja zmiennych\n",
    "    - Detekcja outlierów.\n",
    "2. Optymalizacja modelu:\n",
    "    - Wykorzystanie jednego z poznanych algorytmów optymalizacyjnych.\n",
    "    - W przypadku niezadowalających wyników, testy na innym algorytmie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data preprocessing\n",
    "- Pobranie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych - liczba wypożyczeń\n",
    "df = pd.read_parquet('data/hourly_data_per_station.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych - liczba zwrotów\n",
    "df_agg_ret=pd.read_parquet('data/hourly_data_per_station_returns.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wstępne sprawdzenie danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df_agg_ret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "df_agg_ret.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Przekodowanie zmiennej czasowej na datę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# departure date\n",
    "df['departure_date_hours'] = pd.to_datetime(df['departure_date_hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return date\n",
    "df_agg_ret['return_date_hours'] = pd.to_datetime(df_agg_ret['return_date_hours'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Stworzenie zmiennych z daty: godzina,miesiąc, kwartał."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['departure_date_hours'].dt.hour\n",
    "df['month'] = df['departure_date_hours'].dt.month\n",
    "df['quarter'] = df['departure_date_hours'].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stworzenie nowej zmiennej kategorycznej (y): Czy liczba wypożyczeń w bieżącej godzinie jest większa niż liczba zwrotów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polaczenie danych\n",
    "df_merged = df.merge(df_agg_ret[['return_date_hours','return_id','nr_of_returns']], left_on =[\n",
    "    'departure_id', 'departure_date_hours'], right_on=['return_id','return_date_hours'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wielkosci poszczegolnych ramek\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzenie wartosci pustych\n",
    "df_merged[df_merged['nr_of_returns'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputacja danych\n",
    "df_merged['nr_of_returns'] = df_merged['nr_of_returns'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmienna y kategoryczna\n",
    "df_merged['y_cat'] = (((df_merged['nr_of_departures']-1) > df_merged['nr_of_returns'])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udział wartosci y\n",
    "df_merged['y_cat'].value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Enkoding zmiennej departure id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obiekt taretencoder\n",
    "te = TargetEncoder(target_type='continuous').fit(df_merged[['departure_id']],df_merged['nr_of_departures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodanie zmiennej enkodowanej\n",
    "df_merged['departure_id_encoded'] = te.transform(df_merged[['departure_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzenie - head\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stworzenie lagów (wartości z poprzednich okresów):\n",
    "\n",
    "    - wartości dla danej stacji z poprzedniej godziny\n",
    "    - średnie wartości dla stacji z poprzedniego dnia\n",
    "    - średnie wartości ogółu z poprzedniego dnia i godziny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobranie stworzonych funkcji\n",
    "from help_function import agg_data, lag_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kalkulacja lagów\n",
    "lag_cols = ['nr_of_departures','nr_of_returns','Air temperature (degC)','distance (m)','duration (sec.)','y_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stworzenie daty z dokładnoscia do dnia\n",
    "df_merged[\"departure_date\"] = df_merged['departure_date_hours'].dt.date\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregacja danych do dnia\n",
    "daily_data = agg_data(df_merged,'departure_date',{\n",
    "    'nr_of_departures': 'sum',\n",
    "    'Air temperature (degC)': 'mean',\n",
    "    'distance (m)': 'mean',\n",
    "    'duration (sec.)': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmiana nazw kolumn\n",
    "daily_data.columns = ['yt_' + i for i in daily_data.columns]\n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyznaczenie wczorajszej daty\n",
    "df_merged[\"yesterday_date\"] = df_merged['departure_date'] - pd.Timedelta(days=1)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# połączenie ramek danych\n",
    "print(df_merged.shape)\n",
    "df_merged = df_merged.merge(\n",
    "    daily_data, left_on = 'yesterday_date', right_on='yt_departure_date', how='left').fillna(0)\n",
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dane dzienne per stacja\n",
    "daily_data_station = agg_data(df_merged,['departure_date','departure_id'],{\n",
    "    'nr_of_departures': 'sum',\n",
    "    'Air temperature (degC)': 'mean',\n",
    "    'distance (m)': 'mean',\n",
    "    'duration (sec.)': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmiana nazw kolumn\n",
    "daily_data_station.columns = ['yt_station_' + i for i in daily_data_station.columns]\n",
    "daily_data_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# połączenie ramek danych\n",
    "print(df_merged.shape)\n",
    "df_merged = df_merged.merge(\n",
    "    daily_data_station, \n",
    "    left_on = ['yesterday_date','departure_id'], \n",
    "    right_on=['yt_station_departure_date','yt_station_departure_id'], \n",
    "    how='left').fillna(0)\n",
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stworzenie funkcji prepare data, która przetworzy ramkę danych i doda do niej wymagane zmienne do późniejszej predykcji modelu\n",
    "def prepare_data(df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selekcja zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector, RFE\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kolumny w ramce danych\n",
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista potencjalnych zmiennych\n",
    "potential_x_names = ['departure_id_encoded','Air temperature (degC)','nr_of_departures_lag_1',\n",
    "       'nr_of_returns_lag_1', 'Air temperature (degC)_lag_1',\n",
    "       'distance (m)_lag_1', 'duration (sec.)_lag_1','yt_nr_of_departures',\n",
    "       'yt_Air temperature (degC)', 'yt_distance (m)', 'yt_duration (sec.)',\n",
    "       'yt_station_nr_of_departures', 'yt_station_Air temperature (degC)',\n",
    "       'yt_station_distance (m)', 'yt_station_duration (sec.)'\n",
    "       ]\n",
    "len(potential_x_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selekcja zmiennych\n",
    "seq = RFE(estimator=DecisionTreeClassifier(max_depth=5),n_features_to_select=10)\n",
    "seq.fit(df_merged[potential_x_names],df_merged['y_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista finalnych zmiennych\n",
    "x_names = seq.get_feature_names_out()\n",
    "x_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detekcja outlierów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja obiektu\n",
    "iso_forest = IsolationForest(bootstrap=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "iso_forest.fit(df_merged[x_names[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predyckaj outlierów\n",
    "is_outlier = iso_forest.predict(df_merged[x_names[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udział\n",
    "pd.Series(is_outlier).value_counts()/df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodanie outlierow do danych\n",
    "df_merged['outlier'] = is_outlier\n",
    "df_wo_outliers = df_merged[df_merged['outlier']==1].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Optymalizacja modelu:\n",
    "    - Wykorzystanie jednego z poznanych algorytmów optymalizacyjnych.\n",
    "    - W przypadku niezadowalających wyników, testy na innym algorytmie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimalna data dla każdej stacji\n",
    "min_date = df_wo_outliers.groupby('departure_id')['departure_date'].min().reset_index().rename(\n",
    "    columns={'departure_date':'min_date'})\n",
    "min_date['min_date'] = pd.to_datetime(min_date['min_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacje do odrzucenia \n",
    "stations_to_exclude = min_date[min_date['min_date']>'2019-12-31']['departure_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrowanie\n",
    "df_wo_outliers = df_wo_outliers.merge(min_date, on ='departure_id')\n",
    "df_wo_outliers = df_wo_outliers[~(df_wo_outliers['departure_id'].isin(stations_to_exclude))]\n",
    "df_wo_outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "df_wo_outliers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konwersja na daty\n",
    "df_wo_outliers['departure_date'] = pd.to_datetime(df_wo_outliers['departure_date'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podzial na train / test / valid\n",
    "train = df_wo_outliers[(df_wo_outliers['departure_date']> df_wo_outliers['min_date']) & (df_wo_outliers['departure_date']<='2019-12-31')]\n",
    "test = df_wo_outliers[(df_wo_outliers['departure_date']>'2019-12-31') & (df_wo_outliers['departure_date']<='2020-06-30')]\n",
    "valid = df_wo_outliers[(df_wo_outliers['departure_date']>'2020-07-01') ]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podzial na x/y\n",
    "train_x = train[x_names]\n",
    "train_y = train['y_cat']\n",
    "test_x = test[x_names]\n",
    "test_y = test['y_cat']\n",
    "valid_x = valid[x_names]\n",
    "valid_y = valid['y_cat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical('model_name',['adaboost','randomforest'])\n",
    "    params = {'n_estimators':trial.suggest_int('n_estimators',1,200),\n",
    "              'max_depth': trial.suggest_int('max_depth',1,10),\n",
    "              'min_samples_split': trial.suggest_int('min_samples_split',10,100)}\n",
    "    if model_name =='adaboost':\n",
    "            params['max_iter'] = params['n_estimators']\n",
    "            del params['n_estimators']\n",
    "            model =HistGradientBoostingClassifier(**params).fit(train_x, train_y)\n",
    "    else:\n",
    "        model = RandomForestClassifier(**params).fit(train_x,train_y)\n",
    "    preds = model.predict_proba(test_x)[:,1]\n",
    "    return roc_auc_score(test_y,preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study= optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model \n",
    "final_model = HistGradientBoostingClassifier(**study.best_params).fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predykcje\n",
    "valid_pred = final_model.predict(valid_x)\n",
    "valid_pred_proba = final_model.predict_proba(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation - classification report\n",
    "print(classification_report(valid_y, valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc auc\n",
    "roc_auc_score(valid_y,valid_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapis modelu\n",
    "joblib.dump(final_model, 'models/alert_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
